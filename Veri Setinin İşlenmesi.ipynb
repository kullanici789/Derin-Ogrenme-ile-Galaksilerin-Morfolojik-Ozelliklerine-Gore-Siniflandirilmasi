{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import sqlite3\n",
    "import time\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME_MAPPINGS = \"data/gz2_filename_mapping.csv\"\n",
    "HART16 = \"data/gz2_hart16.csv\"\n",
    "ORIGINAL_IMAGES_DIR = \"data/images/\"\n",
    "PROCESSED_IMAGES_DIR = \"data/images_processed/\"\n",
    "RANDOM_STATE = 32\n",
    "TRAIN_IMAGES_DIR = \"data/train_images/\"\n",
    "TEST_IMAGES_DIR = \"data/test_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_hart = {\n",
    "    \"dr7objid\": \"Int64\",\n",
    "    \"ra\": float,\n",
    "    \"dec\": float,\n",
    "    \"rastring\": str,\n",
    "    \"decstring\": str,\n",
    "    \"sample\": str,\n",
    "    \"gz2_class\": str,\n",
    "    \"total_classifications\": int,\n",
    "    \"total_votes\": int,\n",
    "    \"t01_smooth_or_features_a01_smooth_count\": int,\n",
    "    \"t01_smooth_or_features_a01_smooth_weight\": float,\n",
    "    \"t01_smooth_or_features_a01_smooth_fraction\": float,\n",
    "    \"t01_smooth_or_features_a01_smooth_weighted_fraction\": float,\n",
    "    \"t01_smooth_or_features_a01_smooth_debiased\": float,\n",
    "    \"t01_smooth_or_features_a01_smooth_flag\": int,\n",
    "    \"t01_smooth_or_features_a02_features_or_disk_count\": int,\n",
    "    \"t01_smooth_or_features_a02_features_or_disk_weight\": float,\n",
    "    \"t01_smooth_or_features_a02_features_or_disk_fraction\": float,\n",
    "    \"t01_smooth_or_features_a02_features_or_disk_weighted_fraction\": float,\n",
    "    \"t01_smooth_or_features_a02_features_or_disk_debiased\": float,\n",
    "    \"t01_smooth_or_features_a02_features_or_disk_flag\": int,\n",
    "    \"t01_smooth_or_features_a03_star_or_artifact_count\": int,\n",
    "    \"t01_smooth_or_features_a03_star_or_artifact_weight\": float,\n",
    "    \"t01_smooth_or_features_a03_star_or_artifact_fraction\": float,\n",
    "    \"t01_smooth_or_features_a03_star_or_artifact_weighted_fraction\": float,\n",
    "    \"t01_smooth_or_features_a03_star_or_artifact_debiased\": float,\n",
    "    \"t01_smooth_or_features_a03_star_or_artifact_flag\": int,\n",
    "    \"t02_edgeon_a04_yes_count\": int,\n",
    "    \"t02_edgeon_a04_yes_weight\": float,\n",
    "    \"t02_edgeon_a04_yes_fraction\": float,\n",
    "    \"t02_edgeon_a04_yes_weighted_fraction\": float,\n",
    "    \"t02_edgeon_a04_yes_debiased\": float,\n",
    "    \"t02_edgeon_a04_yes_flag\": int,\n",
    "    \"t02_edgeon_a05_no_count\": int,\n",
    "    \"t02_edgeon_a05_no_weight\": float,\n",
    "    \"t02_edgeon_a05_no_fraction\": float,\n",
    "    \"t02_edgeon_a05_no_weighted_fraction\": float,\n",
    "    \"t02_edgeon_a05_no_debiased\": float,\n",
    "    \"t02_edgeon_a05_no_flag\": int,\n",
    "    \"t03_bar_a06_bar_count\": int,\n",
    "    \"t03_bar_a06_bar_weight\": float,\n",
    "    \"t03_bar_a06_bar_fraction\": float,\n",
    "    \"t03_bar_a06_bar_weighted_fraction\": float,\n",
    "    \"t03_bar_a06_bar_debiased\": float,\n",
    "    \"t03_bar_a06_bar_flag\": int,\n",
    "    \"t03_bar_a07_no_bar_count\": int,\n",
    "    \"t03_bar_a07_no_bar_weight\": float,\n",
    "    \"t03_bar_a07_no_bar_fraction\": float,\n",
    "    \"t03_bar_a07_no_bar_weighted_fraction\": float,\n",
    "    \"t03_bar_a07_no_bar_debiased\": float,\n",
    "    \"t03_bar_a07_no_bar_flag\": int,\n",
    "    \"t04_spiral_a08_spiral_count\": int,\n",
    "    \"t04_spiral_a08_spiral_weight\": float,\n",
    "    \"t04_spiral_a08_spiral_fraction\": float,\n",
    "    \"t04_spiral_a08_spiral_weighted_fraction\": float,\n",
    "    \"t04_spiral_a08_spiral_debiased\": float,\n",
    "    \"t04_spiral_a08_spiral_flag\": int,\n",
    "    \"t04_spiral_a09_no_spiral_count\": int,\n",
    "    \"t04_spiral_a09_no_spiral_weight\": float,\n",
    "    \"t04_spiral_a09_no_spiral_fraction\": float,\n",
    "    \"t04_spiral_a09_no_spiral_weighted_fraction\": float,\n",
    "    \"t04_spiral_a09_no_spiral_debiased\": float,\n",
    "    \"t04_spiral_a09_no_spiral_flag\": int,\n",
    "    \"t05_bulge_prominence_a10_no_bulge_count\": int,\n",
    "    \"t05_bulge_prominence_a10_no_bulge_weight\": float,\n",
    "    \"t05_bulge_prominence_a10_no_bulge_fraction\": float,\n",
    "    \"t05_bulge_prominence_a10_no_bulge_weighted_fraction\": float,\n",
    "    \"t05_bulge_prominence_a10_no_bulge_debiased\": float,\n",
    "    \"t05_bulge_prominence_a10_no_bulge_flag\": int,\n",
    "    \"t05_bulge_prominence_a11_just_noticeable_count\": int,\n",
    "    \"t05_bulge_prominence_a11_just_noticeable_weight\": float,\n",
    "    \"t05_bulge_prominence_a11_just_noticeable_fraction\": float,\n",
    "    \"t05_bulge_prominence_a11_just_noticeable_weighted_fraction\": float,\n",
    "    \"t05_bulge_prominence_a11_just_noticeable_debiased\": float,\n",
    "    \"t05_bulge_prominence_a11_just_noticeable_flag\": int,\n",
    "    \"t05_bulge_prominence_a12_obvious_count\": int,\n",
    "    \"t05_bulge_prominence_a12_obvious_weight\": float,\n",
    "    \"t05_bulge_prominence_a12_obvious_fraction\": float,\n",
    "    \"t05_bulge_prominence_a12_obvious_weighted_fraction\": float,\n",
    "    \"t05_bulge_prominence_a12_obvious_debiased\": float,\n",
    "    \"t05_bulge_prominence_a12_obvious_flag\": int,\n",
    "    \"t05_bulge_prominence_a13_dominant_count\": int,\n",
    "    \"t05_bulge_prominence_a13_dominant_weight\": float,\n",
    "    \"t05_bulge_prominence_a13_dominant_fraction\": float,\n",
    "    \"t05_bulge_prominence_a13_dominant_weighted_fraction\": float,\n",
    "    \"t05_bulge_prominence_a13_dominant_debiased\": float,\n",
    "    \"t05_bulge_prominence_a13_dominant_flag\": int,\n",
    "    \"t06_odd_a14_yes_count\": int,\n",
    "    \"t06_odd_a14_yes_weight\": float,\n",
    "    \"t06_odd_a14_yes_fraction\": float,\n",
    "    \"t06_odd_a14_yes_weighted_fraction\": float,\n",
    "    \"t06_odd_a14_yes_debiased\": float,\n",
    "    \"t06_odd_a14_yes_flag\": int,\n",
    "    \"t06_odd_a15_no_count\": int,\n",
    "    \"t06_odd_a15_no_weight\": float,\n",
    "    \"t06_odd_a15_no_fraction\": float,\n",
    "    \"t06_odd_a15_no_weighted_fraction\": float,\n",
    "    \"t06_odd_a15_no_debiased\": float,\n",
    "    \"t06_odd_a15_no_flag\": int,\n",
    "    \"t07_rounded_a16_completely_round_count\": int,\n",
    "    \"t07_rounded_a16_completely_round_weight\": float,\n",
    "    \"t07_rounded_a16_completely_round_fraction\": float,\n",
    "    \"t07_rounded_a16_completely_round_weighted_fraction\": float,\n",
    "    \"t07_rounded_a16_completely_round_debiased\": float,\n",
    "    \"t07_rounded_a16_completely_round_flag\": int,\n",
    "    \"t07_rounded_a17_in_between_count\": int,\n",
    "    \"t07_rounded_a17_in_between_weight\": float,\n",
    "    \"t07_rounded_a17_in_between_fraction\": float,\n",
    "    \"t07_rounded_a17_in_between_weighted_fraction\": float,\n",
    "    \"t07_rounded_a17_in_between_debiased\": float,\n",
    "    \"t07_rounded_a17_in_between_flag\": int,\n",
    "    \"t07_rounded_a18_cigar_shaped_count\": int,\n",
    "    \"t07_rounded_a18_cigar_shaped_weight\": float,\n",
    "    \"t07_rounded_a18_cigar_shaped_fraction\": float,\n",
    "    \"t07_rounded_a18_cigar_shaped_weighted_fraction\": float,\n",
    "    \"t07_rounded_a18_cigar_shaped_debiased\": float,\n",
    "    \"t07_rounded_a18_cigar_shaped_flag\": int,\n",
    "    \"t08_odd_feature_a19_ring_count\": int,\n",
    "    \"t08_odd_feature_a19_ring_weight\": float,\n",
    "    \"t08_odd_feature_a19_ring_fraction\": float,\n",
    "    \"t08_odd_feature_a19_ring_weighted_fraction\": float,\n",
    "    \"t08_odd_feature_a19_ring_debiased\": float,\n",
    "    \"t08_odd_feature_a19_ring_flag\": int,\n",
    "    \"t08_odd_feature_a20_lens_or_arc_count\": int,\n",
    "    \"t08_odd_feature_a20_lens_or_arc_weight\": float,\n",
    "    \"t08_odd_feature_a20_lens_or_arc_fraction\": float,\n",
    "    \"t08_odd_feature_a20_lens_or_arc_weighted_fraction\": float,\n",
    "    \"t08_odd_feature_a20_lens_or_arc_debiased\": float,\n",
    "    \"t08_odd_feature_a20_lens_or_arc_flag\": int,\n",
    "    \"t08_odd_feature_a21_disturbed_count\": int,\n",
    "    \"t08_odd_feature_a21_disturbed_weight\": float,\n",
    "    \"t08_odd_feature_a21_disturbed_fraction\": float,\n",
    "    \"t08_odd_feature_a21_disturbed_weighted_fraction\": float,\n",
    "    \"t08_odd_feature_a21_disturbed_debiased\": float,\n",
    "    \"t08_odd_feature_a21_disturbed_flag\": int,\n",
    "    \"t08_odd_feature_a22_irregular_count\": int,\n",
    "    \"t08_odd_feature_a22_irregular_weight\": float,\n",
    "    \"t08_odd_feature_a22_irregular_fraction\": float,\n",
    "    \"t08_odd_feature_a22_irregular_weighted_fraction\": float,\n",
    "    \"t08_odd_feature_a22_irregular_debiased\": float,\n",
    "    \"t08_odd_feature_a22_irregular_flag\": int,\n",
    "    \"t08_odd_feature_a23_other_count\": int,\n",
    "    \"t08_odd_feature_a23_other_weight\": float,\n",
    "    \"t08_odd_feature_a23_other_fraction\": float,\n",
    "    \"t08_odd_feature_a23_other_weighted_fraction\": float,\n",
    "    \"t08_odd_feature_a23_other_debiased\": float,\n",
    "    \"t08_odd_feature_a23_other_flag\": int,\n",
    "    \"t08_odd_feature_a24_merger_count\": int,\n",
    "    \"t08_odd_feature_a24_merger_weight\": float,\n",
    "    \"t08_odd_feature_a24_merger_fraction\": float,\n",
    "    \"t08_odd_feature_a24_merger_weighted_fraction\": float,\n",
    "    \"t08_odd_feature_a24_merger_debiased\": float,\n",
    "    \"t08_odd_feature_a24_merger_flag\": int,\n",
    "    \"t08_odd_feature_a38_dust_lane_count\": int,\n",
    "    \"t08_odd_feature_a38_dust_lane_weight\": float,\n",
    "    \"t08_odd_feature_a38_dust_lane_fraction\": float,\n",
    "    \"t08_odd_feature_a38_dust_lane_weighted_fraction\": float,\n",
    "    \"t08_odd_feature_a38_dust_lane_debiased\": float,\n",
    "    \"t08_odd_feature_a38_dust_lane_flag\": int,\n",
    "    \"t09_bulge_shape_a25_rounded_count\": int,\n",
    "    \"t09_bulge_shape_a25_rounded_weight\": float,\n",
    "    \"t09_bulge_shape_a25_rounded_fraction\": float,\n",
    "    \"t09_bulge_shape_a25_rounded_weighted_fraction\": float,\n",
    "    \"t09_bulge_shape_a25_rounded_debiased\": float,\n",
    "    \"t09_bulge_shape_a25_rounded_flag\": int,\n",
    "    \"t09_bulge_shape_a26_boxy_count\": int,\n",
    "    \"t09_bulge_shape_a26_boxy_weight\": float,\n",
    "    \"t09_bulge_shape_a26_boxy_fraction\": float,\n",
    "    \"t09_bulge_shape_a26_boxy_weighted_fraction\": float,\n",
    "    \"t09_bulge_shape_a26_boxy_debiased\": float,\n",
    "    \"t09_bulge_shape_a26_boxy_flag\": int,\n",
    "    \"t09_bulge_shape_a27_no_bulge_count\": int,\n",
    "    \"t09_bulge_shape_a27_no_bulge_weight\": float,\n",
    "    \"t09_bulge_shape_a27_no_bulge_fraction\": float,\n",
    "    \"t09_bulge_shape_a27_no_bulge_weighted_fraction\": float,\n",
    "    \"t09_bulge_shape_a27_no_bulge_debiased\": float,\n",
    "    \"t09_bulge_shape_a27_no_bulge_flag\": int,\n",
    "    \"t10_arms_winding_a28_tight_count\": int,\n",
    "    \"t10_arms_winding_a28_tight_weight\": float,\n",
    "    \"t10_arms_winding_a28_tight_fraction\": float,\n",
    "    \"t10_arms_winding_a28_tight_weighted_fraction\": float,\n",
    "    \"t10_arms_winding_a28_tight_debiased\": float,\n",
    "    \"t10_arms_winding_a28_tight_flag\": int,\n",
    "    \"t10_arms_winding_a29_medium_count\": int,\n",
    "    \"t10_arms_winding_a29_medium_weight\": float,\n",
    "    \"t10_arms_winding_a29_medium_fraction\": float,\n",
    "    \"t10_arms_winding_a29_medium_weighted_fraction\": float,\n",
    "    \"t10_arms_winding_a29_medium_debiased\": float,\n",
    "    \"t10_arms_winding_a29_medium_flag\": int,\n",
    "    \"t10_arms_winding_a30_loose_count\": int,\n",
    "    \"t10_arms_winding_a30_loose_weight\": float,\n",
    "    \"t10_arms_winding_a30_loose_fraction\": float,\n",
    "    \"t10_arms_winding_a30_loose_weighted_fraction\": float,\n",
    "    \"t10_arms_winding_a30_loose_debiased\": float,\n",
    "    \"t10_arms_winding_a30_loose_flag\": int,\n",
    "    \"t11_arms_number_a31_1_count\": int,\n",
    "    \"t11_arms_number_a31_1_weight\": float,\n",
    "    \"t11_arms_number_a31_1_fraction\": float,\n",
    "    \"t11_arms_number_a31_1_weighted_fraction\": float,\n",
    "    \"t11_arms_number_a31_1_debiased\": float,\n",
    "    \"t11_arms_number_a31_1_flag\": int,\n",
    "    \"t11_arms_number_a32_2_count\": int,\n",
    "    \"t11_arms_number_a32_2_weight\": float,\n",
    "    \"t11_arms_number_a32_2_fraction\": float,\n",
    "    \"t11_arms_number_a32_2_weighted_fraction\": float,\n",
    "    \"t11_arms_number_a32_2_debiased\": float,\n",
    "    \"t11_arms_number_a32_2_flag\": int,\n",
    "    \"t11_arms_number_a33_3_count\": int,\n",
    "    \"t11_arms_number_a33_3_weight\": float,\n",
    "    \"t11_arms_number_a33_3_fraction\": float,\n",
    "    \"t11_arms_number_a33_3_weighted_fraction\": float,\n",
    "    \"t11_arms_number_a33_3_debiased\": float,\n",
    "    \"t11_arms_number_a33_3_flag\": int,\n",
    "    \"t11_arms_number_a34_4_count\": int,\n",
    "    \"t11_arms_number_a34_4_weight\": float,\n",
    "    \"t11_arms_number_a34_4_fraction\": float,\n",
    "    \"t11_arms_number_a34_4_weighted_fraction\": float,\n",
    "    \"t11_arms_number_a34_4_debiased\": float,\n",
    "    \"t11_arms_number_a34_4_flag\": int,\n",
    "    \"t11_arms_number_a36_more_than_4_count\": int,\n",
    "    \"t11_arms_number_a36_more_than_4_weight\": float,\n",
    "    \"t11_arms_number_a36_more_than_4_fraction\": float,\n",
    "    \"t11_arms_number_a36_more_than_4_weighted_fraction\": float,\n",
    "    \"t11_arms_number_a36_more_than_4_debiased\": float,\n",
    "    \"t11_arms_number_a36_more_than_4_flag\": int,\n",
    "    \"t11_arms_number_a37_cant_tell_count\": int,\n",
    "    \"t11_arms_number_a37_cant_tell_weight\": float,\n",
    "    \"t11_arms_number_a37_cant_tell_fraction\": float,\n",
    "    \"t11_arms_number_a37_cant_tell_weighted_fraction\": float,\n",
    "    \"t11_arms_number_a37_cant_tell_debiased\": float,\n",
    "    \"t11_arms_number_a37_cant_tell_flag\": int\n",
    "}\n",
    "\n",
    "hart_keep = [\"dr7objid\", \"ra\", \"dec\", \"gz2_class\"]\n",
    "for col_name in dtype_hart.keys():\n",
    "    if col_name.endswith(\"_debiased\"):\n",
    "        hart_keep.append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mappings = pd.read_csv(FILENAME_MAPPINGS,\n",
    "                          header=0,\n",
    "                          dtype={\"objid\": \"Int64\",\n",
    "                                 \"sample\": str,\n",
    "                                 \"asset_id\": int})\n",
    "df_mappings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hart16 = pd.read_csv(HART16,\n",
    "                        header=0,\n",
    "                        dtype=dtype_hart,\n",
    "                        usecols=hart_keep)\n",
    "df_hart16.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mappings.duplicated(\"objid\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hart16.duplicated(\"dr7objid\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dupe_df_mappings = df_mappings[df_mappings.duplicated(\"objid\", keep=False)]\\\n",
    "                                .sort_values(\"asset_id\")\\\n",
    "                                .reset_index(drop=True)\n",
    "_dupe_id_first = _dupe_df_mappings['asset_id'].iloc[0]\n",
    "_dupe_id_last = _dupe_df_mappings['asset_id'].iloc[-1]\n",
    "print(f\"asset_id in objid duplicates: First: {_dupe_id_first}, Last: {_dupe_id_last}, diff:{_dupe_id_last-_dupe_id_first}, count:{_dupe_df_mappings.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mappings_clean = df_mappings[df_mappings[\"asset_id\"] < 295306]\n",
    "df_mappings_clean.duplicated(\"objid\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = pd.merge(df_mappings_clean, df_hart16,\n",
    "                     left_on=\"objid\",\n",
    "                     right_on=\"dr7objid\",\n",
    "                     how=\"inner\",\n",
    "                     validate=\"one_to_one\",\n",
    "                     sort=False)\n",
    "print(df_joined.shape)\n",
    "print(df_joined.isnull().any(axis=1).sum())\n",
    "df_joined.dropna(inplace=True)\n",
    "print(df_joined.shape)\n",
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = glob.glob(ORIGINAL_IMAGES_DIR + \"*.jpg\")\n",
    "print(len(image_files))\n",
    "\n",
    "regex = re.compile(r\"images/(\\d*)\\.jpg\")\n",
    "image_names = [int(re.search(regex, img).group(1)) for img in image_files]\n",
    "image_names.sort()\n",
    "image_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_asset = df_joined[\"asset_id\"].to_list()\n",
    "\n",
    "not_in_images = list(set(table_asset) - set(image_names))\n",
    "print(len(not_in_images))\n",
    "\n",
    "not_in_table = list(set(image_names) - set(table_asset))\n",
    "print(len(not_in_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_clean = df_joined[~df_joined[\"asset_id\"].isin(not_in_images)]\n",
    "df_joined_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gz2class_vc = df_hart16[\"gz2_class\"].value_counts()\n",
    "print(\"Total classes:\", gz2class_vc.shape[0])\n",
    "\n",
    "very_rare_classes = gz2class_vc.loc[gz2class_vc < 12]\n",
    "very_rare_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_spiral_arm_and_winding = re.compile(r\"([1234+?][tml])\")\n",
    "\n",
    "def convert_rare_class(original_class_name: str) -> str:\n",
    "    if not original_class_name.endswith(\")\"):\n",
    "        return original_class_name\n",
    "  \n",
    "    if original_class_name.startswith(\"E\"):\n",
    "        return original_class_name\n",
    "\n",
    "    rare_feature = original_class_name[-3:]\n",
    "    \n",
    "    re_match = re.search(regex_spiral_arm_and_winding, original_class_name)\n",
    "    if re_match is not None:\n",
    "        shape_bar_bulge = original_class_name[:-5]\n",
    "        return shape_bar_bulge + rare_feature\n",
    "    else:\n",
    "        return original_class_name\n",
    "\n",
    "very_rare_class_mapping = {}\n",
    "for orig_class_name in very_rare_classes.index.to_list():\n",
    "    new_name = convert_rare_class(orig_class_name)\n",
    "    very_rare_class_mapping[orig_class_name] = new_name\n",
    "\n",
    "print(len(very_rare_classes.index.to_list()))\n",
    "print(len(set(very_rare_class_mapping.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined_clean[\"class_reduced\"] = df_joined_clean[\"gz2_class\"].replace(very_rare_class_mapping)\n",
    "print(df_joined_clean[\"class_reduced\"].value_counts().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = df_joined_clean[\"class_reduced\"].value_counts()\n",
    "vc_super_rare = vc[vc <= 3]\n",
    "super_rare_class_mapping = {}\n",
    "for orig_class_name in vc_super_rare.index.to_list():\n",
    "    super_rare_class_mapping[orig_class_name] = \"SuperRare\"\n",
    "\n",
    "df_joined_clean[\"class_reduced\"] = df_joined_clean[\"class_reduced\"].replace(super_rare_class_mapping)\n",
    "print(df_joined_clean[\"class_reduced\"].value_counts().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_joined_clean.shape)\n",
    "df_joined_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = sqlite3.connect(\"data/galaxy_data.sqlite\")\n",
    "df_joined_clean.to_sql(\"galaxy_data\", connection, index=False, if_exists=\"replace\")\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [text.replace(\"_debiased\", \"\") for text in hart_keep[4:]]\n",
    "feature_distribution = (df_joined_clean[hart_keep[4:]] > 0.5).sum()\n",
    "display(feature_distribution)\n",
    "ax = feature_distribution.plot.bar(figsize=(16, 6))\n",
    "ax.set_xticklabels(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_CONTOUR_AREA = 100  \n",
    "IMAGE_CENTER = (212, 212)\n",
    "RECT_106_START = IMAGE_CENTER[0] - 106//2\n",
    "RECT_212_START = IMAGE_CENTER[0] - 212//2\n",
    "RECT_106_END = RECT_106_START + 106\n",
    "RECT_212_END = RECT_212_START + 212\n",
    "TARGET_SIZE = (106, 106)\n",
    "\n",
    "def process_image(image_name: str, save_dir: str = None, visualize: bool = False):\n",
    "    image_orig = cv2.imread(f\"{ORIGINAL_IMAGES_DIR}{image_name}.jpg\")\n",
    "\n",
    "    gray = cv2.cvtColor(image_orig, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    ret, thresh = cv2.threshold(blurred, 30, 255, 0)  \n",
    "\n",
    "    element = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(5, 5))\n",
    "    dilated = cv2.dilate(thresh, element, iterations=1)\n",
    "\n",
    "    contours, _ = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    contour_info = []\n",
    "    acceptable_contours = []\n",
    "    for contour in contours:\n",
    "        contour_area = cv2.contourArea(contour)\n",
    "        if contour_area < MIN_CONTOUR_AREA:\n",
    "            continue\n",
    "\n",
    "        M = cv2.moments(contour)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            contour_center = (cX, cY)\n",
    "        else:\n",
    "            continue\n",
    "        dist_to_center = distance.euclidean(IMAGE_CENTER, contour_center)\n",
    "        contour_info.append((contour, dist_to_center))\n",
    "        if visualize:\n",
    "            acceptable_contours.append(contour)\n",
    "\n",
    "    closest_contour = min(contour_info, key = lambda x: x[1])[0]\n",
    "\n",
    "    if visualize:\n",
    "        img_contour = image_orig.copy()\n",
    "        cv2.drawContours(img_contour, acceptable_contours, -1, (0,255,0), 1)\n",
    "        cv2.drawContours(img_contour, [closest_contour], -1, (0, 0, 255), 2)\n",
    "\n",
    "    br_x, br_y, br_w, br_h = cv2.boundingRect(closest_contour)\n",
    "    if visualize:\n",
    "        img_bounding_rect = image_orig.copy()\n",
    "        cv2.drawContours(img_bounding_rect, [closest_contour], -1, (0, 0, 255), 2)\n",
    "        cv2.rectangle(img_bounding_rect, (br_x, br_y), (br_x + br_w, br_y + br_h), (0, 0, 255), 2)\n",
    "\n",
    "   \n",
    "    if visualize:\n",
    "        img_targets = image_orig.copy()\n",
    "        cv2.rectangle(img_targets, (br_x, br_y), (br_x + br_w, br_y + br_h), (0, 0, 255), 2)  \n",
    "        cv2.rectangle(img_targets, (RECT_106_START, RECT_106_START), (RECT_106_END, RECT_106_END), (0, 255, 0), 2)  \n",
    "        cv2.rectangle(img_targets, (RECT_212_START, RECT_212_START), (RECT_212_END, RECT_212_END), (0, 255, 255), 2)  \n",
    "\n",
    "    in_106_rect = False\n",
    "    in_212_rect = False\n",
    "    if br_x >= RECT_106_START and br_y >= RECT_106_START and br_x + br_w <= RECT_106_END and br_y + br_h <= RECT_106_END:\n",
    "        in_106_rect = True\n",
    "    elif br_x >= RECT_212_START and br_y >= RECT_212_START and br_x + br_w <= RECT_212_END and br_y + br_h <= RECT_212_END:\n",
    "        in_212_rect = True\n",
    "\n",
    "    if in_106_rect:\n",
    "        final_image = gray[RECT_106_START:RECT_106_END, RECT_106_START:RECT_106_END]\n",
    "    elif in_212_rect:\n",
    "        cropped_image = gray[RECT_212_START:RECT_212_END, RECT_212_START:RECT_212_END]\n",
    "        final_image = cv2.resize(cropped_image, TARGET_SIZE)\n",
    "    else:\n",
    "        final_image = cv2.resize(gray, TARGET_SIZE)\n",
    "\n",
    "    if save_dir is not None:\n",
    "        cv2.imwrite(f\"{save_dir}{image_name}.png\", final_image)\n",
    "\n",
    "    if visualize:\n",
    "        print(\"In 106:\", in_106_rect, \"In 212\", in_212_rect)\n",
    "        plt.figure()\n",
    "        f, ax = plt.subplots(2, 4, figsize=(13, 6.2))\n",
    "        ax[0][0].imshow(cv2.cvtColor(image_orig, cv2.COLOR_BGR2RGB))\n",
    "        ax[0][1].imshow(blurred, cmap='gray', vmin=0, vmax=255)\n",
    "        ax[0][2].imshow(thresh, cmap='gray', vmin=0, vmax=255)\n",
    "        ax[0][3].imshow(dilated, cmap='gray', vmin=0, vmax=255)\n",
    "        ax[1][0].imshow(cv2.cvtColor(img_contour, cv2.COLOR_BGR2RGB))\n",
    "        ax[1][1].imshow(cv2.cvtColor(img_bounding_rect, cv2.COLOR_BGR2RGB))\n",
    "        ax[1][2].imshow(cv2.cvtColor(img_targets, cv2.COLOR_BGR2RGB))\n",
    "        ax[1][3].imshow(final_image, cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "        ax[0][0].set_title(\"Orijinal\")\n",
    "        ax[0][1].set_title(\"Gaussian Blur\")\n",
    "        ax[0][2].set_title(\"Eşikleme\")\n",
    "        ax[0][3].set_title(\"Genleşme\")\n",
    "        ax[1][0].set_title(\"Kontur\")\n",
    "        ax[1][1].set_title(\"Sınırlayıcı Kutu\")\n",
    "        ax[1][2].set_title(\"Hedefi Kırp/Ölçekleme\")\n",
    "        ax[1][3].set_title(\"Son Görüntü\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_image(\"1541\", save_dir=None, visualize=True)\n",
    "process_image(\"4002\", save_dir=None, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(glob.glob(PROCESSED_IMAGES_DIR + \"*.png\")) >= 1\\\n",
    "    or len(glob.glob(TRAIN_IMAGES_DIR + \"*.png\")) >= 1\\\n",
    "    or len(glob.glob(TEST_IMAGES_DIR + \"*.png\")) >= 1:\n",
    "    raise KeyboardInterrupt\n",
    "\n",
    "start_process_time = time.time()\n",
    "\n",
    "current_image = 0\n",
    "for image in image_names:\n",
    "    if image in not_in_table:\n",
    "        continue\n",
    "    try:\n",
    "        process_image(image, save_dir=PROCESSED_IMAGES_DIR, visualize=False)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Image `{image}` failed to process (current_image int= `{current_image}`)\")\n",
    "        traceback.print_exc()\n",
    "        break\n",
    "    current_image += 1\n",
    "    if current_image % 10_000 == 0:\n",
    "        print(f\"  Processed {current_image:,} image files\")\n",
    "        \n",
    "\n",
    "_hr, _remainder = divmod(time.time() - start_process_time, 3600)\n",
    "_min, _sec = divmod(_remainder, 60)\n",
    "print(f\"--- Time Taken: {int(_hr):02d}:{int(_min):02d}:{int(_sec):02d} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image_files = glob.glob(PROCESSED_IMAGES_DIR + \"*.png\")\n",
    "print(len(processed_image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (len(glob.glob(PROCESSED_IMAGES_DIR + \"*.png\")) >= 1\n",
    "        and len(glob.glob(TRAIN_IMAGES_DIR + \"*.png\")) == 0\n",
    "        and len(glob.glob(TEST_IMAGES_DIR + \"*.png\")) == 0):\n",
    "      raise KeyboardInterrupt\n",
    "\n",
    "stratify_data = df_joined_clean[\"class_reduced\"].values\n",
    "x_image_id_names = df_joined_clean[\"asset_id\"]\n",
    "_junk_y = np.zeros((x_image_id_names.shape[0], 2), dtype=np.int8)\n",
    "print(\"asset_id column is sorted:\", x_image_id_names.is_monotonic_increasing)\n",
    "\n",
    "X_train_assets, X_test_assets, _yj_train, _yj_test = train_test_split(x_image_id_names,\n",
    "                                                                      _junk_y,\n",
    "                                                                      random_state=RANDOM_STATE,\n",
    "                                                                      stratify=stratify_data)\n",
    "\n",
    "for image_name in X_train_assets:\n",
    "    Path(f\"{PROCESSED_IMAGES_DIR}{image_name}.png\").rename(f\"{TRAIN_IMAGES_DIR}{image_name}.png\")\n",
    "for image_name in X_test_assets:\n",
    "    Path(f\"{PROCESSED_IMAGES_DIR}{image_name}.png\").rename(f\"{TEST_IMAGES_DIR}{image_name}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
